{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8657411,"sourceType":"datasetVersion","datasetId":5186582},{"sourceId":8892989,"sourceType":"datasetVersion","datasetId":5348070}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport imgaug.augmenters as iaa\nimport cv2\n\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport imgaug.augmenters as iaa\nfrom multiprocessing import Pool\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom keras import layers, activations\nfrom sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score\nimport seaborn as sns\nimport shutil\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:07:33.633392Z","iopub.execute_input":"2024-08-16T08:07:33.634150Z","iopub.status.idle":"2024-08-16T08:07:58.513215Z","shell.execute_reply.started":"2024-08-16T08:07:33.634118Z","shell.execute_reply":"2024-08-16T08:07:58.512126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def copie_images(s,d,n):\n    os.makedirs(d, exist_ok=True)\n    files = os.listdir(s)\n    image_files = [file for file in files if file.lower().endswith(('.png','.PNG','JPG','jpg'))]\n    for image in image_files[:n]:\n        src_path = os.path.join(s, image)\n        dest_path = os.path.join(d, image)\n        shutil.copy(src_path, dest_path)\n    print(\"Copie terminÃ©e.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:07.520895Z","iopub.execute_input":"2024-08-16T08:08:07.521491Z","iopub.status.idle":"2024-08-16T08:08:07.527816Z","shell.execute_reply.started":"2024-08-16T08:08:07.521459Z","shell.execute_reply":"2024-08-16T08:08:07.526855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_images_in_directory(directory):\n  num_images = 0\n  for filename in os.listdir(directory):\n    if filename.endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp','.JPG','PNG')):\n       num_images += 1\n\n  return num_images","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:10.621020Z","iopub.execute_input":"2024-08-16T08:08:10.621414Z","iopub.status.idle":"2024-08-16T08:08:10.626959Z","shell.execute_reply.started":"2024-08-16T08:08:10.621383Z","shell.execute_reply":"2024-08-16T08:08:10.625865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef load_images_from_folder(folder, num_images=100):\n    images = []\n    for filename in os.listdir(folder):\n        img_path = os.path.join(folder, filename)\n        if os.path.isfile(img_path):\n            img = cv2.imread(img_path)\n            if img is not None:\n                images.append(img)\n            if len(images) >= num_images:\n                break\n    return images\n\ndef display_images(images):\n    num_images = len(images)\n    cols = 10# Number of columns for the grid display\n    rows = num_images // cols + (num_images % cols > 0)  # Compute number of rows needed\n\n    plt.figure(figsize=(20, 20))  # Adjust figure size as needed\n    for i, img in enumerate(images):\n        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n        plt.subplot(rows, cols, i + 1)\n        plt.imshow(img_rgb)\n        plt.axis('off')\n    plt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:13.000949Z","iopub.execute_input":"2024-08-16T08:08:13.001300Z","iopub.status.idle":"2024-08-16T08:08:13.010040Z","shell.execute_reply.started":"2024-08-16T08:08:13.001271Z","shell.execute_reply":"2024-08-16T08:08:13.009041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_folder = '/kaggle/input/base-copiedelocale-cropped-image/Croped_image_male_femelle/femelle'\nnum_images_to_display = 100\n\nimages = load_images_from_folder(input_folder, num_images_to_display)\ndisplay_images(images)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:16.622461Z","iopub.execute_input":"2024-08-16T08:08:16.623137Z","iopub.status.idle":"2024-08-16T08:08:28.832100Z","shell.execute_reply.started":"2024-08-16T08:08:16.623104Z","shell.execute_reply":"2024-08-16T08:08:28.830641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"male='/kaggle/input/base-copiedelocale-cropped-image/Croped_image_male_femelle/male'\nm=count_images_in_directory(male)\n\n\nfemelle='/kaggle/input/base-copiedelocale-cropped-image/Croped_image_male_femelle/femelle'\nf=count_images_in_directory(femelle)\nprint(\"male\", m)\nprint(\"femelle\",f)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:36.094746Z","iopub.execute_input":"2024-08-16T08:08:36.095392Z","iopub.status.idle":"2024-08-16T08:08:36.411017Z","shell.execute_reply.started":"2024-08-16T08:08:36.095361Z","shell.execute_reply":"2024-08-16T08:08:36.409965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nlabels = [\"male\", \"femelle\"]\nvalues = [m, f]\ncolors = [\"gold\", \"mediumturquoise\"]\n\nfig = go.Figure(\n    data=[\n        go.Pie(\n            labels=labels,\n            values=values,\n            textfont_size=20,\n            marker=dict(colors=colors, pattern=dict(shape=[\".\", \"x\"]))\n        )\n    ]\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:46.482045Z","iopub.execute_input":"2024-08-16T08:08:46.482400Z","iopub.status.idle":"2024-08-16T08:08:46.495161Z","shell.execute_reply.started":"2024-08-16T08:08:46.482367Z","shell.execute_reply":"2024-08-16T08:08:46.493977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport random\n\ndef zoom_image(image, zoom_factor):\n    height, width = image.shape[:2]\n    new_height, new_width = int(height / zoom_factor), int(width / zoom_factor)\n    start_row = (height - new_height) // 2\n    start_col = (width - new_width) // 2\n    end_row = start_row + new_height\n    end_col = start_col + new_width\n    cropped_image = image[start_row:end_row, start_col:end_col]\n    zoomed_image = cv2.resize(cropped_image, (width, height), interpolation=cv2.INTER_LINEAR)\n    return zoomed_image\n\ndef add_gaussian_noise(image, mean=0, stddev=25):\n    gauss = np.random.normal(mean, stddev, image.shape).astype('uint8')\n    noisy_image = cv2.add(image, gauss)\n    return noisy_image\n\ndef translate_image_random_fill(image, x, y):\n    h, w = image.shape[:2]\n    M = np.float32([[1, 0, x], [0, 1, y]])\n    translated = cv2.warpAffine(image, M, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n    if x > 0:\n        translated[:, :x] = np.random.randint(0, 256, (h, x, 3), dtype=np.uint8)\n    elif x < 0:\n        translated[:, x:] = np.random.randint(0, 256, (h, -x, 3), dtype=np.uint8)\n    if y > 0:\n        translated[:y, :] = np.random.randint(0, 256, (y, w, 3), dtype=np.uint8)\n    elif y < 0:\n        translated[y:, :] = np.random.randint(0, 256, (-y, w, 3), dtype=np.uint8)\n    return translated\n\n\n\n\ndef rotate_image(image, angle):\n    (h, w) = image.shape[:2]\n    center = (w / 2, h / 2)\n    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n    rotated = cv2.warpAffine(image, M, (w, h))\n    return rotated\n\n\ndef random_rotate_image(image, min_angle=-20, max_angle=20):\n    angle = random.uniform(min_angle, max_angle)\n    return rotate_image(image, angle)\n\n\ndef adjust_brightness(image, value):\n    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(np.float32)\n    hsv[:, :, 2] += value\n    hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)\n    hsv = hsv.astype(np.uint8)\n    brightened_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n    return brightened_image\n\ndef flip_image(image, flip_code):\n    return cv2.flip(image, flip_code)\n\n\ndef convert_to_grayscale(image):\n    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\ndef process_and_save_images(input_folder, output_folder, c):\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    image_files = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n\n    augmentations = [\n        lambda img: zoom_image(img, random.uniform(1.1, 1.5)),\n        lambda img: translate_image_random_fill(img, random.randint(-20, 20), random.randint(-20, 20)),\n        lambda img: adjust_brightness(img, random.randint(-50, 50)),\n        lambda img: flip_image(img, 0),  # Horizontal flip\n        lambda img: flip_image(img, 1),  # Vertical flip\n        lambda img: random_rotate_image(img),\n        lambda img: convert_to_grayscale(img)  # Convertir en niveaux de gris\n    ]\n\n    for i, file_name in enumerate(image_files):\n        img = cv2.imread(os.path.join(input_folder, file_name))\n        img_name, img_ext = os.path.splitext(file_name)\n\n        # Appliquer chaque augmentation 14 fois\n        for aug in augmentations:\n            for j in range(c):\n                aug_img = aug(img.copy())\n                # VÃ©rifier si l'image est en niveaux de gris et ajuster le nom de fichier\n                if len(aug_img.shape) == 2:  # L'image est en niveaux de gris\n                    output_file_name = f\"{img_name}_gray_aug_{j}{img_ext}\"\n                else:\n                    output_file_name = f\"{img_name}_aug_{j}{img_ext}\"\n                \n                cv2.imwrite(os.path.join(output_folder, output_file_name), aug_img)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:09:10.261672Z","iopub.execute_input":"2024-08-16T08:09:10.262294Z","iopub.status.idle":"2024-08-16T08:09:10.285761Z","shell.execute_reply.started":"2024-08-16T08:09:10.262262Z","shell.execute_reply":"2024-08-16T08:09:10.284824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:51.793681Z","iopub.execute_input":"2024-08-16T08:08:51.794049Z","iopub.status.idle":"2024-08-16T08:08:51.799038Z","shell.execute_reply.started":"2024-08-16T08:08:51.794018Z","shell.execute_reply":"2024-08-16T08:08:51.797712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_dir(path):\n     os.system(f'rm -rf {path}')","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:58.901147Z","iopub.execute_input":"2024-08-16T08:08:58.901916Z","iopub.status.idle":"2024-08-16T08:08:58.906012Z","shell.execute_reply.started":"2024-08-16T08:08:58.901883Z","shell.execute_reply":"2024-08-16T08:08:58.905083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_dir(\"/kaggle/working/gray_Image/M\")\ncreate_dir(\"/kaggle/working/gray_Image/f\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:09:01.186877Z","iopub.execute_input":"2024-08-16T08:09:01.187656Z","iopub.status.idle":"2024-08-16T08:09:01.191729Z","shell.execute_reply.started":"2024-08-16T08:09:01.187625Z","shell.execute_reply":"2024-08-16T08:09:01.190877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_folder = '/kaggle/input/base-copiedelocale-cropped-image/Croped_image_male_femelle/femelle'\noutput_folder = '/kaggle/working/gray_Image/f'\nprocess_and_save_images(input_folder, output_folder,3)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:09:15.310195Z","iopub.execute_input":"2024-08-16T08:09:15.310562Z","iopub.status.idle":"2024-08-16T08:13:03.284648Z","shell.execute_reply.started":"2024-08-16T08:09:15.310533Z","shell.execute_reply":"2024-08-16T08:13:03.283849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_folder = '/kaggle/input/base-copiedelocale-cropped-image/Croped_image_male_femelle/male'\noutput_folder = '/kaggle/working/gray_Image/M'\nprocess_and_save_images(input_folder, output_folder,3)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:16:54.243751Z","iopub.execute_input":"2024-08-16T08:16:54.244550Z","iopub.status.idle":"2024-08-16T08:23:22.655427Z","shell.execute_reply.started":"2024-08-16T08:16:54.244518Z","shell.execute_reply":"2024-08-16T08:23:22.654360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"male='/kaggle/working/gray_Image/M'\nm=count_images_in_directory(male)\n\n\nfemelle='/kaggle/working/gray_Image/f'\nf=count_images_in_directory(femelle)\nprint(\"male\",m)\nprint(\"femelle\",f)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:29:58.194295Z","iopub.execute_input":"2024-08-16T08:29:58.195119Z","iopub.status.idle":"2024-08-16T08:29:58.209379Z","shell.execute_reply.started":"2024-08-16T08:29:58.195084Z","shell.execute_reply":"2024-08-16T08:29:58.208402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_dir(\"/kaggle/working/gray_Image/femelle\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:30:06.200882Z","iopub.execute_input":"2024-08-16T08:30:06.201227Z","iopub.status.idle":"2024-08-16T08:30:06.205831Z","shell.execute_reply.started":"2024-08-16T08:30:06.201200Z","shell.execute_reply":"2024-08-16T08:30:06.204884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_dir(\"/kaggle/working/gray_Image/male\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:30:13.321369Z","iopub.execute_input":"2024-08-16T08:30:13.321764Z","iopub.status.idle":"2024-08-16T08:30:13.326367Z","shell.execute_reply.started":"2024-08-16T08:30:13.321732Z","shell.execute_reply":"2024-08-16T08:30:13.325482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=2748\ns = '/kaggle/working/gray_Image/M'\nd ='/kaggle/working/gray_Image/male'\ncopie_images(s,d,n)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:30:22.340297Z","iopub.execute_input":"2024-08-16T08:30:22.340832Z","iopub.status.idle":"2024-08-16T08:30:23.906313Z","shell.execute_reply.started":"2024-08-16T08:30:22.340797Z","shell.execute_reply":"2024-08-16T08:30:23.905393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"remove_dir(\"/kaggle/working/gray_Image/M\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:30:41.087938Z","iopub.execute_input":"2024-08-16T08:30:41.088312Z","iopub.status.idle":"2024-08-16T08:30:41.095856Z","shell.execute_reply.started":"2024-08-16T08:30:41.088281Z","shell.execute_reply":"2024-08-16T08:30:41.094743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=2748\ns = '/kaggle/working/gray_Image/f'\nd ='/kaggle/working/gray_Image/femelle'\ncopie_images(s,d,n)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:31:03.381179Z","iopub.execute_input":"2024-08-16T08:31:03.382101Z","iopub.status.idle":"2024-08-16T08:31:04.428025Z","shell.execute_reply.started":"2024-08-16T08:31:03.382057Z","shell.execute_reply":"2024-08-16T08:31:04.427012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" remove_dir(\"/kaggle/working/gray_Image/f\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:31:15.490648Z","iopub.execute_input":"2024-08-16T08:31:15.490996Z","iopub.status.idle":"2024-08-16T08:31:15.719564Z","shell.execute_reply.started":"2024-08-16T08:31:15.490970Z","shell.execute_reply":"2024-08-16T08:31:15.718755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"male='/kaggle/working/gray_Image/male'\nm=count_images_in_directory(male)\n\n\nfemelle='/kaggle/working/gray_Image/femelle'\nf=count_images_in_directory(femelle)\nprint(\"male\",m)\nprint(\"femelle\",f)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:31:25.020115Z","iopub.execute_input":"2024-08-16T08:31:25.020454Z","iopub.status.idle":"2024-08-16T08:31:25.032787Z","shell.execute_reply.started":"2024-08-16T08:31:25.020427Z","shell.execute_reply":"2024-08-16T08:31:25.031790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nlabels = [\"male\", \"femelle\"]\nvalues = [m, f]\ncolors = [\"gold\", \"mediumturquoise\"]\n\nfig = go.Figure(\n    data=[\n        go.Pie(\n            labels=labels,\n            values=values,\n            textfont_size=20,\n            marker=dict(colors=colors, pattern=dict(shape=[\".\", \"x\"]))\n        )\n    ]\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:32:39.653419Z","iopub.execute_input":"2024-08-16T08:32:39.654236Z","iopub.status.idle":"2024-08-16T08:32:39.666220Z","shell.execute_reply.started":"2024-08-16T08:32:39.654203Z","shell.execute_reply":"2024-08-16T08:32:39.665311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install split-folders","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:32:57.298449Z","iopub.execute_input":"2024-08-16T08:32:57.298825Z","iopub.status.idle":"2024-08-16T08:33:13.482032Z","shell.execute_reply.started":"2024-08-16T08:32:57.298796Z","shell.execute_reply":"2024-08-16T08:33:13.480796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_dir(\"/kaggle/working/BaseSplited\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:33:36.425015Z","iopub.execute_input":"2024-08-16T08:33:36.425826Z","iopub.status.idle":"2024-08-16T08:33:36.431042Z","shell.execute_reply.started":"2024-08-16T08:33:36.425789Z","shell.execute_reply":"2024-08-16T08:33:36.429992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import splitfolders  \n\ninput_folder = \"/kaggle/working/gray_Image\"  \noutput_folder = '/kaggle/working/BaseSplited'  \n\nsplitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.7, .3))","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:33:51.152076Z","iopub.execute_input":"2024-08-16T08:33:51.152428Z","iopub.status.idle":"2024-08-16T08:33:53.571810Z","shell.execute_reply.started":"2024-08-16T08:33:51.152400Z","shell.execute_reply":"2024-08-16T08:33:53.570842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils.class_weight import compute_class_weight\n\ntrain_dir = '/kaggle/working/BaseSplited/train'\nval_dir = '/kaggle/working/BaseSplited/val'\n\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator(rescale=1./255)\n\nbatch_size = 16\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(600, 600),\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=(600, 600),\n    batch_size=batch_size,\n    class_mode='binary'\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:34:12.544340Z","iopub.execute_input":"2024-08-16T08:34:12.544725Z","iopub.status.idle":"2024-08-16T08:34:12.732743Z","shell.execute_reply.started":"2024-08-16T08:34:12.544695Z","shell.execute_reply":"2024-08-16T08:34:12.731948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nimport os\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:38:05.860759Z","iopub.execute_input":"2024-08-16T08:38:05.861145Z","iopub.status.idle":"2024-08-16T08:38:05.866190Z","shell.execute_reply.started":"2024-08-16T08:38:05.861113Z","shell.execute_reply":"2024-08-16T08:38:05.865236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential  \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization  \nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint  \n\n# DÃ©finir le modÃ¨le  \nmodel1 = Sequential([  \n    # PremiÃ¨re sÃ©rie de couches Convolution + MaxPooling\n    Conv2D(128, (7, 7), activation='relu', padding='same', input_shape=(600, 600, 3)),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),  \n    \n    Conv2D(128, (7, 7), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),\n    \n    # DeuxiÃ¨me sÃ©rie de couches Convolution + MaxPooling\n    Conv2D(64, (5, 5), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),  \n    \n    Conv2D(64, (5, 5), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)), \n    \n    # TroisiÃ¨me sÃ©rie de couches Convolution + MaxPooling\n    Conv2D(64, (3, 3), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),\n    \n    Conv2D(32, (3, 3), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),  \n    \n    Conv2D(32, (3, 3), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),\n    \n    Conv2D(32, (3, 3), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),  \n    \n    # Couche Flatten\n    Flatten(),  \n    \n    # PremiÃ¨re couche fully connected\n    Dense(512, activation='relu'),  \n    Dropout(0.5),  \n    \n    # DeuxiÃ¨me couche fully connected\n    Dense(256, activation='relu'),  \n    Dropout(0.5),  \n    \n    # TroisiÃ¨me couche fully connected\n    Dense(128, activation='relu'),  \n    Dropout(0.5),  \n    \n    # Couche de sortie\n    Dense(1, activation='sigmoid')  # 'softmax' pour plus de deux classes  \n])  \n\nmodel1.compile(optimizer='adam',  \n              loss='binary_crossentropy',  # 'categorical_crossentropy' pour plus de deux classes  \n              metrics=['accuracy'])  \n\n# Callbacks avec la bonne extension  \nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)  \nmodel_checkpoint = ModelCheckpoint('_model1.keras', save_best_only=True)  # Changez l'extension ici  \n\n# RÃ©sumÃ© du modÃ¨le  \nmodel1.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:38:10.609260Z","iopub.execute_input":"2024-08-16T08:38:10.609634Z","iopub.status.idle":"2024-08-16T08:38:12.014991Z","shell.execute_reply.started":"2024-08-16T08:38:10.609598Z","shell.execute_reply":"2024-08-16T08:38:12.014094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculer les poids des classes\ny_true = train_generator.classes\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_true), y=y_true)\nclass_weights_dict = dict(enumerate(class_weights))\n\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)  \nmodel_checkpoint = ModelCheckpoint('_model1.keras', save_best_only=True)  \n\nhistory3 = model1.fit(\n    train_generator,\n    epochs=20,\n    validation_data=val_generator,\n    class_weight=class_weights_dict,\n    callbacks=[early_stopping, model_checkpoint]\n)\n\n\ny_pred = model1.predict(val_generator)\ny_pred_classes = (y_pred > 0.5).astype(\"int32\").flatten()\ny_true = val_generator.classes\n\nbalanced_accuracy = balanced_accuracy_score(y_true, y_pred_classes)\nprint(f'Balanced Accuracy: {balanced_accuracy}')\n\nprint(classification_report(y_true, y_pred_classes))","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:38:19.901702Z","iopub.execute_input":"2024-08-16T08:38:19.902037Z","iopub.status.idle":"2024-08-16T10:44:29.512870Z","shell.execute_reply.started":"2024-08-16T08:38:19.902011Z","shell.execute_reply":"2024-08-16T10:44:29.511762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_true = train_generator.classes\n# class_weights = compute_class_weight('balanced', classes=np.unique(y_true), y=y_true)\n# class_weights_dict = dict(enumerate(class_weights))\n\n\n# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)  \n# model_checkpoint = ModelCheckpoint('_model1.keras', save_best_only=True)  \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_true)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:55:47.084847Z","iopub.execute_input":"2024-08-16T10:55:47.085750Z","iopub.status.idle":"2024-08-16T10:55:47.091085Z","shell.execute_reply.started":"2024-08-16T10:55:47.085714Z","shell.execute_reply":"2024-08-16T10:55:47.090084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(class_weights )","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:56:11.220250Z","iopub.execute_input":"2024-08-16T10:56:11.220611Z","iopub.status.idle":"2024-08-16T10:56:11.225426Z","shell.execute_reply.started":"2024-08-16T10:56:11.220571Z","shell.execute_reply":"2024-08-16T10:56:11.224513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights_dict","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:56:27.367842Z","iopub.execute_input":"2024-08-16T10:56:27.368199Z","iopub.status.idle":"2024-08-16T10:56:27.374561Z","shell.execute_reply.started":"2024-08-16T10:56:27.368170Z","shell.execute_reply":"2024-08-16T10:56:27.373726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:56:46.412610Z","iopub.execute_input":"2024-08-16T10:56:46.413305Z","iopub.status.idle":"2024-08-16T10:56:46.419045Z","shell.execute_reply.started":"2024-08-16T10:56:46.413269Z","shell.execute_reply":"2024-08-16T10:56:46.418084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:57:03.163961Z","iopub.execute_input":"2024-08-16T10:57:03.164644Z","iopub.status.idle":"2024-08-16T10:57:03.170434Z","shell.execute_reply.started":"2024-08-16T10:57:03.164604Z","shell.execute_reply":"2024-08-16T10:57:03.169503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:57:46.073124Z","iopub.execute_input":"2024-08-16T10:57:46.073953Z","iopub.status.idle":"2024-08-16T10:57:46.080319Z","shell.execute_reply.started":"2024-08-16T10:57:46.073918Z","shell.execute_reply":"2024-08-16T10:57:46.079261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_classes","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:58:16.992617Z","iopub.execute_input":"2024-08-16T10:58:16.993551Z","iopub.status.idle":"2024-08-16T10:58:16.999467Z","shell.execute_reply.started":"2024-08-16T10:58:16.993516Z","shell.execute_reply":"2024-08-16T10:58:16.998443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:58:58.964743Z","iopub.execute_input":"2024-08-16T10:58:58.965095Z","iopub.status.idle":"2024-08-16T10:58:58.971393Z","shell.execute_reply.started":"2024-08-16T10:58:58.965067Z","shell.execute_reply":"2024-08-16T10:58:58.970432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Charger un lot d'images de test\ntest_images, test_labels = next(val_generator)\n\n# Afficher quelques images avec leurs Ã©tiquettes\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    plt.imshow(test_images[i])\n    plt.title(f\"Label: {int(test_labels[i])}\")\n    plt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:59:41.812654Z","iopub.execute_input":"2024-08-16T10:59:41.813278Z","iopub.status.idle":"2024-08-16T10:59:43.375838Z","shell.execute_reply.started":"2024-08-16T10:59:41.813246Z","shell.execute_reply":"2024-08-16T10:59:43.374650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nfrom PIL import Image\n\ndef display_random_images(directory, num_images=5):\n    all_images = os.listdir(directory)\n    random_images = random.sample(all_images, num_images)\n    \n    plt.figure(figsize=(10, 10))\n    for i, img_name in enumerate(random_images):\n        img_path = os.path.join(directory, img_name)\n        img = Image.open(img_path)\n        plt.subplot(1, num_images, i+1)\n        plt.imshow(img)\n        plt.title(img_name)\n        plt.axis('off')\n    plt.show()\n\n# Afficher des images alÃ©atoires pour vÃ©rifier les Ã©tiquettes\ndisplay_random_images('/kaggle/working/BaseSplited/val/male')\ndisplay_random_images('/kaggle/working/BaseSplited/val/femelle')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:03:24.172369Z","iopub.execute_input":"2024-08-16T11:03:24.172829Z","iopub.status.idle":"2024-08-16T11:03:25.331387Z","shell.execute_reply.started":"2024-08-16T11:03:24.172799Z","shell.execute_reply":"2024-08-16T11:03:25.330487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspecter les premiÃ¨res images et leurs Ã©tiquettes dans le gÃ©nÃ©rateur de donnÃ©es\nfor data_batch, labels_batch in train_generator:\n    # Afficher les premiÃ¨res images et leurs Ã©tiquettes\n    for i in range(5):\n        plt.subplot(1, 5, i + 1)\n        plt.imshow(data_batch[i])\n        plt.title(f\"Label: {int(labels_batch[i])}\")\n        plt.axis('off')\n    plt.show()\n    break  # Sortir aprÃ¨s la premiÃ¨re itÃ©ration pour Ã©viter de traiter tout le batch\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:05:43.292478Z","iopub.execute_input":"2024-08-16T11:05:43.293364Z","iopub.status.idle":"2024-08-16T11:05:45.073225Z","shell.execute_reply.started":"2024-08-16T11:05:43.293326Z","shell.execute_reply":"2024-08-16T11:05:45.072264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef verify_labels(directory):\n    datagen = ImageDataGenerator()\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(600, 600),\n        batch_size=1,  # Utiliser un petit batch size pour la vÃ©rification\n        class_mode='binary'  # Supposons une classification binaire\n    )\n    \n    for batch in generator:\n        images, labels = batch\n        # VÃ©rifier la forme de labels pour comprendre la structure\n        print(f\"Labels shape: {labels.shape}\")\n\n        # Si labels est un vecteur one-hot ou une matrice\n        if labels.ndim > 1:\n            for i in range(len(labels)):\n                print(f\"Label: {np.argmax(labels[i])}\")  # Trouver l'index de la classe\n        else:\n            # Si labels est une valeur scalaire\n            for i in range(len(labels)):\n                print(f\"Label: {int(labels[i])}\")\n\n        plt.imshow(images[0])\n        plt.axis('off')\n        plt.show()\n        break  # Sortir aprÃ¨s la premiÃ¨re image pour vÃ©rification\n\n# VÃ©rifiez les rÃ©pertoires de train et de validation\nverify_labels('/kaggle/working/BaseSplited/train')\nverify_labels('/kaggle/working/BaseSplited/val')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:11:13.925669Z","iopub.execute_input":"2024-08-16T11:11:13.926032Z","iopub.status.idle":"2024-08-16T11:11:14.386622Z","shell.execute_reply.started":"2024-08-16T11:11:13.926003Z","shell.execute_reply":"2024-08-16T11:11:14.385657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# PrÃ©dire les Ã©tiquettes pour les donnÃ©es de test\ntest_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=(600, 600),\n    batch_size=1,  # Utiliser un petit batch size pour la vÃ©rification\n    class_mode='binary',\n    shuffle=False  # Important pour garder l'ordre des Ã©chantillons\n)\n\npredictions = model1.predict(test_generator, steps=test_generator.samples, verbose=1)\npredicted_labels = (predictions > 0.5).astype('int32')  # Binariser les prÃ©dictions\n\n# Obtenir les vÃ©ritables Ã©tiquettes\ntrue_labels = test_generator.classes\n\n# Calculer la matrice de confusion\ncm = confusion_matrix(true_labels, predicted_labels)\nprint(\"Confusion Matrix:\")\nprint(cm)\n\n# Afficher le rapport de classification\nreport = classification_report(true_labels, predicted_labels, target_names=test_generator.class_indices.keys())\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:13:33.709543Z","iopub.execute_input":"2024-08-16T11:13:33.709927Z","iopub.status.idle":"2024-08-16T11:14:40.465128Z","shell.execute_reply.started":"2024-08-16T11:13:33.709898Z","shell.execute_reply":"2024-08-16T11:14:40.464119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Obtenir les vÃ©ritables Ã©tiquettes\ntrue_labels = test_generator.classes\n\n# Calculer la matrice de confusion\ncm = confusion_matrix(true_labels, predicted_labels)\n\n# Afficher la matrice de confusion avec Seaborn\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:25:49.677959Z","iopub.execute_input":"2024-08-16T11:25:49.678810Z","iopub.status.idle":"2024-08-16T11:25:49.982223Z","shell.execute_reply.started":"2024-08-16T11:25:49.678779Z","shell.execute_reply":"2024-08-16T11:25:49.981329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\n# PrÃ©dire les probabilitÃ©s pour les donnÃ©es de test\nprobabilities = model1.predict(test_generator, steps=test_generator.samples, verbose=1)\n\n# Obtenir les vÃ©ritables Ã©tiquettes\ntrue_labels = test_generator.classes\n\n# Calculer les courbes ROC\nfpr, tpr, thresholds = roc_curve(true_labels, probabilities)\n\n# Calculer l'AUC\nroc_auc = auc(fpr, tpr)\n\n# Afficher la courbe ROC\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='gray', linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:40:18.757962Z","iopub.execute_input":"2024-08-16T11:40:18.758624Z","iopub.status.idle":"2024-08-16T11:41:17.964497Z","shell.execute_reply.started":"2024-08-16T11:40:18.758571Z","shell.execute_reply":"2024-08-16T11:41:17.963645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_loss, test_accuracy = model1.evaluate(test_generator)\n\n# Affichage des courbes de prÃ©cision\nplt.figure(figsize=(12, 4))\n\n# PrÃ©cision d'entraÃ®nement, de validation et de test\nplt.subplot(1, 2, 1)\nplt.plot(history3.history['accuracy'])\nplt.plot(history3.history['val_accuracy'])\nplt.axhline(y=test_accuracy, color='r', linestyle='--')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n\n# Affichage des courbes de perte (loss)\nplt.subplot(1, 2, 2)\nplt.plot(history3.history['loss'])\nplt.plot(history3.history['val_loss'])\nplt.axhline(y=test_loss, color='g', linestyle='--')\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:49:14.451352Z","iopub.execute_input":"2024-08-16T11:49:14.452097Z","iopub.status.idle":"2024-08-16T11:50:18.394144Z","shell.execute_reply.started":"2024-08-16T11:49:14.452062Z","shell.execute_reply":"2024-08-16T11:50:18.393236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-16T12:17:09.855496Z","iopub.execute_input":"2024-08-16T12:17:09.855916Z","iopub.status.idle":"2024-08-16T12:17:09.861835Z","shell.execute_reply.started":"2024-08-16T12:17:09.855886Z","shell.execute_reply":"2024-08-16T12:17:09.860913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
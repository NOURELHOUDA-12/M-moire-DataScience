{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8657411,"sourceType":"datasetVersion","datasetId":5186582},{"sourceId":8892989,"sourceType":"datasetVersion","datasetId":5348070}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport imgaug.augmenters as iaa\nimport cv2\n\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport imgaug.augmenters as iaa\nfrom multiprocessing import Pool\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom keras import layers, activations\nfrom sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score\nimport seaborn as sns\nimport shutil\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:07:33.633392Z","iopub.execute_input":"2024-08-16T08:07:33.634150Z","iopub.status.idle":"2024-08-16T08:07:58.513215Z","shell.execute_reply.started":"2024-08-16T08:07:33.634118Z","shell.execute_reply":"2024-08-16T08:07:58.512126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def copie_images(s,d,n):\n    os.makedirs(d, exist_ok=True)\n    files = os.listdir(s)\n    image_files = [file for file in files if file.lower().endswith(('.png','.PNG','JPG','jpg'))]\n    for image in image_files[:n]:\n        src_path = os.path.join(s, image)\n        dest_path = os.path.join(d, image)\n        shutil.copy(src_path, dest_path)\n    print(\"Copie terminée.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:07.520895Z","iopub.execute_input":"2024-08-16T08:08:07.521491Z","iopub.status.idle":"2024-08-16T08:08:07.527816Z","shell.execute_reply.started":"2024-08-16T08:08:07.521459Z","shell.execute_reply":"2024-08-16T08:08:07.526855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_images_in_directory(directory):\n  num_images = 0\n  for filename in os.listdir(directory):\n    if filename.endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp','.JPG','PNG')):\n       num_images += 1\n\n  return num_images","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:10.621020Z","iopub.execute_input":"2024-08-16T08:08:10.621414Z","iopub.status.idle":"2024-08-16T08:08:10.626959Z","shell.execute_reply.started":"2024-08-16T08:08:10.621383Z","shell.execute_reply":"2024-08-16T08:08:10.625865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef load_images_from_folder(folder, num_images=100):\n    images = []\n    for filename in os.listdir(folder):\n        img_path = os.path.join(folder, filename)\n        if os.path.isfile(img_path):\n            img = cv2.imread(img_path)\n            if img is not None:\n                images.append(img)\n            if len(images) >= num_images:\n                break\n    return images\n\ndef display_images(images):\n    num_images = len(images)\n    cols = 10# Number of columns for the grid display\n    rows = num_images // cols + (num_images % cols > 0)  # Compute number of rows needed\n\n    plt.figure(figsize=(20, 20))  # Adjust figure size as needed\n    for i, img in enumerate(images):\n        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n        plt.subplot(rows, cols, i + 1)\n        plt.imshow(img_rgb)\n        plt.axis('off')\n    plt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:13.000949Z","iopub.execute_input":"2024-08-16T08:08:13.001300Z","iopub.status.idle":"2024-08-16T08:08:13.010040Z","shell.execute_reply.started":"2024-08-16T08:08:13.001271Z","shell.execute_reply":"2024-08-16T08:08:13.009041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_folder = '/kaggle/input/base-copiedelocale-cropped-image/Croped_image_male_femelle/femelle'\nnum_images_to_display = 100\n\nimages = load_images_from_folder(input_folder, num_images_to_display)\ndisplay_images(images)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:16.622461Z","iopub.execute_input":"2024-08-16T08:08:16.623137Z","iopub.status.idle":"2024-08-16T08:08:28.832100Z","shell.execute_reply.started":"2024-08-16T08:08:16.623104Z","shell.execute_reply":"2024-08-16T08:08:28.830641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"male='/kaggle/input/base-copiedelocale-cropped-image/Croped_image_male_femelle/male'\nm=count_images_in_directory(male)\n\n\nfemelle='/kaggle/input/base-copiedelocale-cropped-image/Croped_image_male_femelle/femelle'\nf=count_images_in_directory(femelle)\nprint(\"male\", m)\nprint(\"femelle\",f)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:36.094746Z","iopub.execute_input":"2024-08-16T08:08:36.095392Z","iopub.status.idle":"2024-08-16T08:08:36.411017Z","shell.execute_reply.started":"2024-08-16T08:08:36.095361Z","shell.execute_reply":"2024-08-16T08:08:36.409965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nlabels = [\"male\", \"femelle\"]\nvalues = [m, f]\ncolors = [\"gold\", \"mediumturquoise\"]\n\nfig = go.Figure(\n    data=[\n        go.Pie(\n            labels=labels,\n            values=values,\n            textfont_size=20,\n            marker=dict(colors=colors, pattern=dict(shape=[\".\", \"x\"]))\n        )\n    ]\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:46.482045Z","iopub.execute_input":"2024-08-16T08:08:46.482400Z","iopub.status.idle":"2024-08-16T08:08:46.495161Z","shell.execute_reply.started":"2024-08-16T08:08:46.482367Z","shell.execute_reply":"2024-08-16T08:08:46.493977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport random\n\ndef zoom_image(image, zoom_factor):\n    height, width = image.shape[:2]\n    new_height, new_width = int(height / zoom_factor), int(width / zoom_factor)\n    start_row = (height - new_height) // 2\n    start_col = (width - new_width) // 2\n    end_row = start_row + new_height\n    end_col = start_col + new_width\n    cropped_image = image[start_row:end_row, start_col:end_col]\n    zoomed_image = cv2.resize(cropped_image, (width, height), interpolation=cv2.INTER_LINEAR)\n    return zoomed_image\n\ndef add_gaussian_noise(image, mean=0, stddev=25):\n    gauss = np.random.normal(mean, stddev, image.shape).astype('uint8')\n    noisy_image = cv2.add(image, gauss)\n    return noisy_image\n\ndef translate_image_random_fill(image, x, y):\n    h, w = image.shape[:2]\n    M = np.float32([[1, 0, x], [0, 1, y]])\n    translated = cv2.warpAffine(image, M, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n    if x > 0:\n        translated[:, :x] = np.random.randint(0, 256, (h, x, 3), dtype=np.uint8)\n    elif x < 0:\n        translated[:, x:] = np.random.randint(0, 256, (h, -x, 3), dtype=np.uint8)\n    if y > 0:\n        translated[:y, :] = np.random.randint(0, 256, (y, w, 3), dtype=np.uint8)\n    elif y < 0:\n        translated[y:, :] = np.random.randint(0, 256, (-y, w, 3), dtype=np.uint8)\n    return translated\n\n\n\n\ndef rotate_image(image, angle):\n    (h, w) = image.shape[:2]\n    center = (w / 2, h / 2)\n    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n    rotated = cv2.warpAffine(image, M, (w, h))\n    return rotated\n\n\ndef random_rotate_image(image, min_angle=-20, max_angle=20):\n    angle = random.uniform(min_angle, max_angle)\n    return rotate_image(image, angle)\n\n\ndef adjust_brightness(image, value):\n    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(np.float32)\n    hsv[:, :, 2] += value\n    hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)\n    hsv = hsv.astype(np.uint8)\n    brightened_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n    return brightened_image\n\ndef flip_image(image, flip_code):\n    return cv2.flip(image, flip_code)\n\n\ndef convert_to_grayscale(image):\n    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\ndef process_and_save_images(input_folder, output_folder, c):\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    image_files = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n\n    augmentations = [\n        lambda img: zoom_image(img, random.uniform(1.1, 1.5)),\n        lambda img: translate_image_random_fill(img, random.randint(-20, 20), random.randint(-20, 20)),\n        lambda img: adjust_brightness(img, random.randint(-50, 50)),\n        lambda img: flip_image(img, 0),  # Horizontal flip\n        lambda img: flip_image(img, 1),  # Vertical flip\n        lambda img: random_rotate_image(img),\n        lambda img: convert_to_grayscale(img)  # Convertir en niveaux de gris\n    ]\n\n    for i, file_name in enumerate(image_files):\n        img = cv2.imread(os.path.join(input_folder, file_name))\n        img_name, img_ext = os.path.splitext(file_name)\n\n        # Appliquer chaque augmentation 14 fois\n        for aug in augmentations:\n            for j in range(c):\n                aug_img = aug(img.copy())\n                # Vérifier si l'image est en niveaux de gris et ajuster le nom de fichier\n                if len(aug_img.shape) == 2:  # L'image est en niveaux de gris\n                    output_file_name = f\"{img_name}_gray_aug_{j}{img_ext}\"\n                else:\n                    output_file_name = f\"{img_name}_aug_{j}{img_ext}\"\n                \n                cv2.imwrite(os.path.join(output_folder, output_file_name), aug_img)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:09:10.261672Z","iopub.execute_input":"2024-08-16T08:09:10.262294Z","iopub.status.idle":"2024-08-16T08:09:10.285761Z","shell.execute_reply.started":"2024-08-16T08:09:10.262262Z","shell.execute_reply":"2024-08-16T08:09:10.284824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:51.793681Z","iopub.execute_input":"2024-08-16T08:08:51.794049Z","iopub.status.idle":"2024-08-16T08:08:51.799038Z","shell.execute_reply.started":"2024-08-16T08:08:51.794018Z","shell.execute_reply":"2024-08-16T08:08:51.797712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_dir(path):\n     os.system(f'rm -rf {path}')","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:08:58.901147Z","iopub.execute_input":"2024-08-16T08:08:58.901916Z","iopub.status.idle":"2024-08-16T08:08:58.906012Z","shell.execute_reply.started":"2024-08-16T08:08:58.901883Z","shell.execute_reply":"2024-08-16T08:08:58.905083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_dir(\"/kaggle/working/gray_Image/M\")\ncreate_dir(\"/kaggle/working/gray_Image/f\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:09:01.186877Z","iopub.execute_input":"2024-08-16T08:09:01.187656Z","iopub.status.idle":"2024-08-16T08:09:01.191729Z","shell.execute_reply.started":"2024-08-16T08:09:01.187625Z","shell.execute_reply":"2024-08-16T08:09:01.190877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_folder = '/kaggle/input/base-copiedelocale-cropped-image/Croped_image_male_femelle/femelle'\noutput_folder = '/kaggle/working/gray_Image/f'\nprocess_and_save_images(input_folder, output_folder,3)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:09:15.310195Z","iopub.execute_input":"2024-08-16T08:09:15.310562Z","iopub.status.idle":"2024-08-16T08:13:03.284648Z","shell.execute_reply.started":"2024-08-16T08:09:15.310533Z","shell.execute_reply":"2024-08-16T08:13:03.283849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_folder = '/kaggle/input/base-copiedelocale-cropped-image/Croped_image_male_femelle/male'\noutput_folder = '/kaggle/working/gray_Image/M'\nprocess_and_save_images(input_folder, output_folder,3)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:16:54.243751Z","iopub.execute_input":"2024-08-16T08:16:54.244550Z","iopub.status.idle":"2024-08-16T08:23:22.655427Z","shell.execute_reply.started":"2024-08-16T08:16:54.244518Z","shell.execute_reply":"2024-08-16T08:23:22.654360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"male='/kaggle/working/gray_Image/M'\nm=count_images_in_directory(male)\n\n\nfemelle='/kaggle/working/gray_Image/f'\nf=count_images_in_directory(femelle)\nprint(\"male\",m)\nprint(\"femelle\",f)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:29:58.194295Z","iopub.execute_input":"2024-08-16T08:29:58.195119Z","iopub.status.idle":"2024-08-16T08:29:58.209379Z","shell.execute_reply.started":"2024-08-16T08:29:58.195084Z","shell.execute_reply":"2024-08-16T08:29:58.208402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_dir(\"/kaggle/working/gray_Image/femelle\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:30:06.200882Z","iopub.execute_input":"2024-08-16T08:30:06.201227Z","iopub.status.idle":"2024-08-16T08:30:06.205831Z","shell.execute_reply.started":"2024-08-16T08:30:06.201200Z","shell.execute_reply":"2024-08-16T08:30:06.204884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_dir(\"/kaggle/working/gray_Image/male\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:30:13.321369Z","iopub.execute_input":"2024-08-16T08:30:13.321764Z","iopub.status.idle":"2024-08-16T08:30:13.326367Z","shell.execute_reply.started":"2024-08-16T08:30:13.321732Z","shell.execute_reply":"2024-08-16T08:30:13.325482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=2748\ns = '/kaggle/working/gray_Image/M'\nd ='/kaggle/working/gray_Image/male'\ncopie_images(s,d,n)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:30:22.340297Z","iopub.execute_input":"2024-08-16T08:30:22.340832Z","iopub.status.idle":"2024-08-16T08:30:23.906313Z","shell.execute_reply.started":"2024-08-16T08:30:22.340797Z","shell.execute_reply":"2024-08-16T08:30:23.905393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"remove_dir(\"/kaggle/working/gray_Image/M\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:30:41.087938Z","iopub.execute_input":"2024-08-16T08:30:41.088312Z","iopub.status.idle":"2024-08-16T08:30:41.095856Z","shell.execute_reply.started":"2024-08-16T08:30:41.088281Z","shell.execute_reply":"2024-08-16T08:30:41.094743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=2748\ns = '/kaggle/working/gray_Image/f'\nd ='/kaggle/working/gray_Image/femelle'\ncopie_images(s,d,n)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:31:03.381179Z","iopub.execute_input":"2024-08-16T08:31:03.382101Z","iopub.status.idle":"2024-08-16T08:31:04.428025Z","shell.execute_reply.started":"2024-08-16T08:31:03.382057Z","shell.execute_reply":"2024-08-16T08:31:04.427012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" remove_dir(\"/kaggle/working/gray_Image/f\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:31:15.490648Z","iopub.execute_input":"2024-08-16T08:31:15.490996Z","iopub.status.idle":"2024-08-16T08:31:15.719564Z","shell.execute_reply.started":"2024-08-16T08:31:15.490970Z","shell.execute_reply":"2024-08-16T08:31:15.718755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"male='/kaggle/working/gray_Image/male'\nm=count_images_in_directory(male)\n\n\nfemelle='/kaggle/working/gray_Image/femelle'\nf=count_images_in_directory(femelle)\nprint(\"male\",m)\nprint(\"femelle\",f)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:31:25.020115Z","iopub.execute_input":"2024-08-16T08:31:25.020454Z","iopub.status.idle":"2024-08-16T08:31:25.032787Z","shell.execute_reply.started":"2024-08-16T08:31:25.020427Z","shell.execute_reply":"2024-08-16T08:31:25.031790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nlabels = [\"male\", \"femelle\"]\nvalues = [m, f]\ncolors = [\"gold\", \"mediumturquoise\"]\n\nfig = go.Figure(\n    data=[\n        go.Pie(\n            labels=labels,\n            values=values,\n            textfont_size=20,\n            marker=dict(colors=colors, pattern=dict(shape=[\".\", \"x\"]))\n        )\n    ]\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:32:39.653419Z","iopub.execute_input":"2024-08-16T08:32:39.654236Z","iopub.status.idle":"2024-08-16T08:32:39.666220Z","shell.execute_reply.started":"2024-08-16T08:32:39.654203Z","shell.execute_reply":"2024-08-16T08:32:39.665311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install split-folders","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:32:57.298449Z","iopub.execute_input":"2024-08-16T08:32:57.298825Z","iopub.status.idle":"2024-08-16T08:33:13.482032Z","shell.execute_reply.started":"2024-08-16T08:32:57.298796Z","shell.execute_reply":"2024-08-16T08:33:13.480796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_dir(\"/kaggle/working/BaseSplited\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:33:36.425015Z","iopub.execute_input":"2024-08-16T08:33:36.425826Z","iopub.status.idle":"2024-08-16T08:33:36.431042Z","shell.execute_reply.started":"2024-08-16T08:33:36.425789Z","shell.execute_reply":"2024-08-16T08:33:36.429992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import splitfolders  \n\ninput_folder = \"/kaggle/working/gray_Image\"  \noutput_folder = '/kaggle/working/BaseSplited'  \n\nsplitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.7, .3))","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:33:51.152076Z","iopub.execute_input":"2024-08-16T08:33:51.152428Z","iopub.status.idle":"2024-08-16T08:33:53.571810Z","shell.execute_reply.started":"2024-08-16T08:33:51.152400Z","shell.execute_reply":"2024-08-16T08:33:53.570842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils.class_weight import compute_class_weight\n\ntrain_dir = '/kaggle/working/BaseSplited/train'\nval_dir = '/kaggle/working/BaseSplited/val'\n\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator(rescale=1./255)\n\nbatch_size = 16\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(600, 600),\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=(600, 600),\n    batch_size=batch_size,\n    class_mode='binary'\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:34:12.544340Z","iopub.execute_input":"2024-08-16T08:34:12.544725Z","iopub.status.idle":"2024-08-16T08:34:12.732743Z","shell.execute_reply.started":"2024-08-16T08:34:12.544695Z","shell.execute_reply":"2024-08-16T08:34:12.731948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nimport os\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:38:05.860759Z","iopub.execute_input":"2024-08-16T08:38:05.861145Z","iopub.status.idle":"2024-08-16T08:38:05.866190Z","shell.execute_reply.started":"2024-08-16T08:38:05.861113Z","shell.execute_reply":"2024-08-16T08:38:05.865236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential  \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization  \nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint  \n\n# Définir le modèle  \nmodel1 = Sequential([  \n    # Première série de couches Convolution + MaxPooling\n    Conv2D(128, (7, 7), activation='relu', padding='same', input_shape=(600, 600, 3)),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),  \n    \n    Conv2D(128, (7, 7), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),\n    \n    # Deuxième série de couches Convolution + MaxPooling\n    Conv2D(64, (5, 5), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),  \n    \n    Conv2D(64, (5, 5), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)), \n    \n    # Troisième série de couches Convolution + MaxPooling\n    Conv2D(64, (3, 3), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),\n    \n    Conv2D(32, (3, 3), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),  \n    \n    Conv2D(32, (3, 3), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),\n    \n    Conv2D(32, (3, 3), activation='relu', padding='same'),  \n    BatchNormalization(),  \n    MaxPooling2D((2, 2)),  \n    \n    # Couche Flatten\n    Flatten(),  \n    \n    # Première couche fully connected\n    Dense(512, activation='relu'),  \n    Dropout(0.5),  \n    \n    # Deuxième couche fully connected\n    Dense(256, activation='relu'),  \n    Dropout(0.5),  \n    \n    # Troisième couche fully connected\n    Dense(128, activation='relu'),  \n    Dropout(0.5),  \n    \n    # Couche de sortie\n    Dense(1, activation='sigmoid')  # 'softmax' pour plus de deux classes  \n])  \n\nmodel1.compile(optimizer='adam',  \n              loss='binary_crossentropy',  # 'categorical_crossentropy' pour plus de deux classes  \n              metrics=['accuracy'])  \n\n# Callbacks avec la bonne extension  \nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)  \nmodel_checkpoint = ModelCheckpoint('_model1.keras', save_best_only=True)  # Changez l'extension ici  \n\n# Résumé du modèle  \nmodel1.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:38:10.609260Z","iopub.execute_input":"2024-08-16T08:38:10.609634Z","iopub.status.idle":"2024-08-16T08:38:12.014991Z","shell.execute_reply.started":"2024-08-16T08:38:10.609598Z","shell.execute_reply":"2024-08-16T08:38:12.014094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculer les poids des classes\ny_true = train_generator.classes\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_true), y=y_true)\nclass_weights_dict = dict(enumerate(class_weights))\n\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)  \nmodel_checkpoint = ModelCheckpoint('_model1.keras', save_best_only=True)  \n\nhistory3 = model1.fit(\n    train_generator,\n    epochs=20,\n    validation_data=val_generator,\n    class_weight=class_weights_dict,\n    callbacks=[early_stopping, model_checkpoint]\n)\n\n\ny_pred = model1.predict(val_generator)\ny_pred_classes = (y_pred > 0.5).astype(\"int32\").flatten()\ny_true = val_generator.classes\n\nbalanced_accuracy = balanced_accuracy_score(y_true, y_pred_classes)\nprint(f'Balanced Accuracy: {balanced_accuracy}')\n\nprint(classification_report(y_true, y_pred_classes))","metadata":{"execution":{"iopub.status.busy":"2024-08-16T08:38:19.901702Z","iopub.execute_input":"2024-08-16T08:38:19.902037Z","iopub.status.idle":"2024-08-16T10:44:29.512870Z","shell.execute_reply.started":"2024-08-16T08:38:19.902011Z","shell.execute_reply":"2024-08-16T10:44:29.511762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_true = train_generator.classes\n# class_weights = compute_class_weight('balanced', classes=np.unique(y_true), y=y_true)\n# class_weights_dict = dict(enumerate(class_weights))\n\n\n# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)  \n# model_checkpoint = ModelCheckpoint('_model1.keras', save_best_only=True)  \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_true)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:55:47.084847Z","iopub.execute_input":"2024-08-16T10:55:47.085750Z","iopub.status.idle":"2024-08-16T10:55:47.091085Z","shell.execute_reply.started":"2024-08-16T10:55:47.085714Z","shell.execute_reply":"2024-08-16T10:55:47.090084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(class_weights )","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:56:11.220250Z","iopub.execute_input":"2024-08-16T10:56:11.220611Z","iopub.status.idle":"2024-08-16T10:56:11.225426Z","shell.execute_reply.started":"2024-08-16T10:56:11.220571Z","shell.execute_reply":"2024-08-16T10:56:11.224513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights_dict","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:56:27.367842Z","iopub.execute_input":"2024-08-16T10:56:27.368199Z","iopub.status.idle":"2024-08-16T10:56:27.374561Z","shell.execute_reply.started":"2024-08-16T10:56:27.368170Z","shell.execute_reply":"2024-08-16T10:56:27.373726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:56:46.412610Z","iopub.execute_input":"2024-08-16T10:56:46.413305Z","iopub.status.idle":"2024-08-16T10:56:46.419045Z","shell.execute_reply.started":"2024-08-16T10:56:46.413269Z","shell.execute_reply":"2024-08-16T10:56:46.418084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:57:03.163961Z","iopub.execute_input":"2024-08-16T10:57:03.164644Z","iopub.status.idle":"2024-08-16T10:57:03.170434Z","shell.execute_reply.started":"2024-08-16T10:57:03.164604Z","shell.execute_reply":"2024-08-16T10:57:03.169503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:57:46.073124Z","iopub.execute_input":"2024-08-16T10:57:46.073953Z","iopub.status.idle":"2024-08-16T10:57:46.080319Z","shell.execute_reply.started":"2024-08-16T10:57:46.073918Z","shell.execute_reply":"2024-08-16T10:57:46.079261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_classes","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:58:16.992617Z","iopub.execute_input":"2024-08-16T10:58:16.993551Z","iopub.status.idle":"2024-08-16T10:58:16.999467Z","shell.execute_reply.started":"2024-08-16T10:58:16.993516Z","shell.execute_reply":"2024-08-16T10:58:16.998443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:58:58.964743Z","iopub.execute_input":"2024-08-16T10:58:58.965095Z","iopub.status.idle":"2024-08-16T10:58:58.971393Z","shell.execute_reply.started":"2024-08-16T10:58:58.965067Z","shell.execute_reply":"2024-08-16T10:58:58.970432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Charger un lot d'images de test\ntest_images, test_labels = next(val_generator)\n\n# Afficher quelques images avec leurs étiquettes\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    plt.imshow(test_images[i])\n    plt.title(f\"Label: {int(test_labels[i])}\")\n    plt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:59:41.812654Z","iopub.execute_input":"2024-08-16T10:59:41.813278Z","iopub.status.idle":"2024-08-16T10:59:43.375838Z","shell.execute_reply.started":"2024-08-16T10:59:41.813246Z","shell.execute_reply":"2024-08-16T10:59:43.374650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nfrom PIL import Image\n\ndef display_random_images(directory, num_images=5):\n    all_images = os.listdir(directory)\n    random_images = random.sample(all_images, num_images)\n    \n    plt.figure(figsize=(10, 10))\n    for i, img_name in enumerate(random_images):\n        img_path = os.path.join(directory, img_name)\n        img = Image.open(img_path)\n        plt.subplot(1, num_images, i+1)\n        plt.imshow(img)\n        plt.title(img_name)\n        plt.axis('off')\n    plt.show()\n\n# Afficher des images aléatoires pour vérifier les étiquettes\ndisplay_random_images('/kaggle/working/BaseSplited/val/male')\ndisplay_random_images('/kaggle/working/BaseSplited/val/femelle')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:03:24.172369Z","iopub.execute_input":"2024-08-16T11:03:24.172829Z","iopub.status.idle":"2024-08-16T11:03:25.331387Z","shell.execute_reply.started":"2024-08-16T11:03:24.172799Z","shell.execute_reply":"2024-08-16T11:03:25.330487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspecter les premières images et leurs étiquettes dans le générateur de données\nfor data_batch, labels_batch in train_generator:\n    # Afficher les premières images et leurs étiquettes\n    for i in range(5):\n        plt.subplot(1, 5, i + 1)\n        plt.imshow(data_batch[i])\n        plt.title(f\"Label: {int(labels_batch[i])}\")\n        plt.axis('off')\n    plt.show()\n    break  # Sortir après la première itération pour éviter de traiter tout le batch\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:05:43.292478Z","iopub.execute_input":"2024-08-16T11:05:43.293364Z","iopub.status.idle":"2024-08-16T11:05:45.073225Z","shell.execute_reply.started":"2024-08-16T11:05:43.293326Z","shell.execute_reply":"2024-08-16T11:05:45.072264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef verify_labels(directory):\n    datagen = ImageDataGenerator()\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(600, 600),\n        batch_size=1,  # Utiliser un petit batch size pour la vérification\n        class_mode='binary'  # Supposons une classification binaire\n    )\n    \n    for batch in generator:\n        images, labels = batch\n        # Vérifier la forme de labels pour comprendre la structure\n        print(f\"Labels shape: {labels.shape}\")\n\n        # Si labels est un vecteur one-hot ou une matrice\n        if labels.ndim > 1:\n            for i in range(len(labels)):\n                print(f\"Label: {np.argmax(labels[i])}\")  # Trouver l'index de la classe\n        else:\n            # Si labels est une valeur scalaire\n            for i in range(len(labels)):\n                print(f\"Label: {int(labels[i])}\")\n\n        plt.imshow(images[0])\n        plt.axis('off')\n        plt.show()\n        break  # Sortir après la première image pour vérification\n\n# Vérifiez les répertoires de train et de validation\nverify_labels('/kaggle/working/BaseSplited/train')\nverify_labels('/kaggle/working/BaseSplited/val')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:11:13.925669Z","iopub.execute_input":"2024-08-16T11:11:13.926032Z","iopub.status.idle":"2024-08-16T11:11:14.386622Z","shell.execute_reply.started":"2024-08-16T11:11:13.926003Z","shell.execute_reply":"2024-08-16T11:11:14.385657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Prédire les étiquettes pour les données de test\ntest_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=(600, 600),\n    batch_size=1,  # Utiliser un petit batch size pour la vérification\n    class_mode='binary',\n    shuffle=False  # Important pour garder l'ordre des échantillons\n)\n\npredictions = model1.predict(test_generator, steps=test_generator.samples, verbose=1)\npredicted_labels = (predictions > 0.5).astype('int32')  # Binariser les prédictions\n\n# Obtenir les véritables étiquettes\ntrue_labels = test_generator.classes\n\n# Calculer la matrice de confusion\ncm = confusion_matrix(true_labels, predicted_labels)\nprint(\"Confusion Matrix:\")\nprint(cm)\n\n# Afficher le rapport de classification\nreport = classification_report(true_labels, predicted_labels, target_names=test_generator.class_indices.keys())\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:13:33.709543Z","iopub.execute_input":"2024-08-16T11:13:33.709927Z","iopub.status.idle":"2024-08-16T11:14:40.465128Z","shell.execute_reply.started":"2024-08-16T11:13:33.709898Z","shell.execute_reply":"2024-08-16T11:14:40.464119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Obtenir les véritables étiquettes\ntrue_labels = test_generator.classes\n\n# Calculer la matrice de confusion\ncm = confusion_matrix(true_labels, predicted_labels)\n\n# Afficher la matrice de confusion avec Seaborn\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:25:49.677959Z","iopub.execute_input":"2024-08-16T11:25:49.678810Z","iopub.status.idle":"2024-08-16T11:25:49.982223Z","shell.execute_reply.started":"2024-08-16T11:25:49.678779Z","shell.execute_reply":"2024-08-16T11:25:49.981329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\n# Prédire les probabilités pour les données de test\nprobabilities = model1.predict(test_generator, steps=test_generator.samples, verbose=1)\n\n# Obtenir les véritables étiquettes\ntrue_labels = test_generator.classes\n\n# Calculer les courbes ROC\nfpr, tpr, thresholds = roc_curve(true_labels, probabilities)\n\n# Calculer l'AUC\nroc_auc = auc(fpr, tpr)\n\n# Afficher la courbe ROC\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='gray', linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:40:18.757962Z","iopub.execute_input":"2024-08-16T11:40:18.758624Z","iopub.status.idle":"2024-08-16T11:41:17.964497Z","shell.execute_reply.started":"2024-08-16T11:40:18.758571Z","shell.execute_reply":"2024-08-16T11:41:17.963645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_loss, test_accuracy = model1.evaluate(test_generator)\n\n# Affichage des courbes de précision\nplt.figure(figsize=(12, 4))\n\n# Précision d'entraînement, de validation et de test\nplt.subplot(1, 2, 1)\nplt.plot(history3.history['accuracy'])\nplt.plot(history3.history['val_accuracy'])\nplt.axhline(y=test_accuracy, color='r', linestyle='--')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n\n# Affichage des courbes de perte (loss)\nplt.subplot(1, 2, 2)\nplt.plot(history3.history['loss'])\nplt.plot(history3.history['val_loss'])\nplt.axhline(y=test_loss, color='g', linestyle='--')\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:49:14.451352Z","iopub.execute_input":"2024-08-16T11:49:14.452097Z","iopub.status.idle":"2024-08-16T11:50:18.394144Z","shell.execute_reply.started":"2024-08-16T11:49:14.452062Z","shell.execute_reply":"2024-08-16T11:50:18.393236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-16T12:17:09.855496Z","iopub.execute_input":"2024-08-16T12:17:09.855916Z","iopub.status.idle":"2024-08-16T12:17:09.861835Z","shell.execute_reply.started":"2024-08-16T12:17:09.855886Z","shell.execute_reply":"2024-08-16T12:17:09.860913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}